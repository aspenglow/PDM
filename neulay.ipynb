{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pdm\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.pool import radius\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "V = lambda x: x.detach().cpu().numpy()\n",
    "from numpy import newaxis, mean, savetxt\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import spatial\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "#GCN -----------\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "#GAT ----------\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "#GN -----------\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "\n",
    "        self.node_mlp_1 = Seq(Lin(self.in_feat, self.in_feat, bias = False), ReLU(), Lin(self.in_feat, self.in_feat, bias = False))\n",
    "        self.node_mlp_2 = Seq(Lin(2*self.in_feat, self.in_feat, bias = False), ReLU(), Lin(self.in_feat, self.out_feat, bias = False))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, col = edge_index\n",
    "        out = x[row]\n",
    "        out = self.node_mlp_1(out)\n",
    "        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        \n",
    "        return self.node_mlp_2(out)\n",
    "    \n",
    "\n",
    "#Loss function -----------\n",
    "\n",
    "MIN_REPUL_DIST = 1e-3\n",
    "radius = .4\n",
    "magnitude = 10\n",
    "\n",
    "def Repulsion(X):\n",
    "    # assuming X: (n,d)\n",
    "    dX = X[newaxis] - X[:,newaxis] # (n,n,d)\n",
    "    # have to remove the diagonal (self-loops)\n",
    "    # dX shouldn't be calc'd for self. \n",
    "    # mask = torch.ones(len(X), len(X))- torch.eye(len(X))\n",
    "    #return torch.sum(1/ (MIN_REPUL_DIST + torch.norm(dX, dim=(-1))))\n",
    "\n",
    "    r = torch.sum( dX**2, dim = -1)\n",
    "    return magnitude*torch.sum(torch.exp( -r/4/(radius**2) ))\n",
    "\n",
    "\n",
    "\n",
    "def Elastic(X, A):\n",
    "    D = torch.diag(torch.sum(A,dim = 1))\n",
    "    # Laplacian\n",
    "    L = D - A \n",
    "    return torch.trace(X.t() @ L @ X)\n",
    "\n",
    "def Loss(X,A,c=1):\n",
    "    return Elastic(X,A) + c * Repulsion(X)\n",
    "\n",
    "\n",
    "def Elastic_edgelist(X, edg):\n",
    "    # if edg.shape[-1] == 2:\n",
    "    return torch.sum((X[edg[:,0]]-X[edg[:,1]])**2)/2\n",
    "    \n",
    "def Loss_edgelist(X,edg,c=1):\n",
    "    return Elastic_edgelist(X,edg) + c * Repulsion(X)\n",
    "\n",
    "\n",
    "#Alternative GCN models ----------- \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, A=None, edgelist=None, N=None):\n",
    "        \"\"\"A: Adjacency matrix \n",
    "        if A is gven, edgelist ignored. \n",
    "        If edglelist given, max index in edgelist is assumed to be number of nodes N, unless N is given. \n",
    "        \"\"\"\n",
    "        super(GCN,self).__init__()\n",
    "        if A!=None:\n",
    "            self.A = torch.as_tensor(A)\n",
    "        elif len(edgelist): \n",
    "            raise\n",
    "            \n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.W = nn.Parameter(torch.empty(in_feat, out_feat))\n",
    "        nn.init.kaiming_normal_(self.W)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.A @ x @ self.W\n",
    "\n",
    "\n",
    "class GCN_Lowrank(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, A=None, pc_num_frac = 0.1, \n",
    "                 edgelist=None, N=None):\n",
    "        \"\"\"A: Adjacency matrix \n",
    "        if A is gven, edgelist ignored. \n",
    "        If edglelist given, max index in edgelist is assumed to be number of nodes N, unless N is given. \n",
    "        \"\"\"\n",
    "        super(GCN_Lowrank,self).__init__()\n",
    "        if A!=None:\n",
    "            self.A = torch.as_tensor(A)\n",
    "            self._prep_A_lowrank(A, pc_num_frac)\n",
    "        elif len(edgelist): \n",
    "            raise\n",
    "            \n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.W = nn.Parameter(torch.empty(in_feat, out_feat))\n",
    "        nn.init.kaiming_normal_(self.W)\n",
    "        \n",
    "    def _prep_A_lowrank(self, A, pc_num_frac):\n",
    "        A = torch.as_tensor(A)\n",
    "        A = (A+A.t())/2\n",
    "        v,p = torch.linalg.eigh(A)\n",
    "        k = int(pc_num_frac * len(A))\n",
    "        idx = torch.argsort(v, descending=True)[:k]\n",
    "        self.pval, self.pvec = v[:k], p[:,:k]\n",
    "        self.pvec_tv = (self.pvec * self.pval).t()\n",
    "        \n",
    "    def agg(self,x):\n",
    "        x = self.pvec_tv @ x\n",
    "        return self.pvec @ x\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # return self.A @ x @ self.W\n",
    "        return self.agg(x) @ self.W\n",
    "\n",
    "    \n",
    "def time_it(f):\n",
    "    def dt(*args, **kw):\n",
    "        t0 = time.time()\n",
    "        a = f(*args, **kw)\n",
    "        print('%s time: %.3g s'%(f.__name__,time.time()-t0))\n",
    "        # return a\n",
    "    return dt\n",
    "\n",
    "#NeuLay model -----------\n",
    "\n",
    "class ResGCN(nn.Module):\n",
    "    def __init__(self, feat_dims = [1,1], A=None, edge_index = None, edgelist=None, normalize_A = True,\n",
    "                activation = None, device = None, lr = 1e-2, GCN_class = GCN):\n",
    "        super(ResGCN,self).__init__()\n",
    "        if device==None:\n",
    "            device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(device)\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        if edgelist!=None:\n",
    "            self.edgelist = torch.tensor(edgelist, dtype = torch.long).to(self.device) \n",
    "            A = torch.zeros(n,n, dtype = torch.float32).to(self.device)\n",
    "            for i,j in self.edgelist:\n",
    "                A[i,j] = 1\n",
    "                # A[j,i] = 1 \n",
    "            self.Loss = lambda x: Loss_edgelist(x,self.edgelist)\n",
    "            self.A = torch.as_tensor(A).to(self.device)\n",
    "        \n",
    "        elif A!=None:\n",
    "            self.A = torch.as_tensor(A).to(self.device)\n",
    "            self.Loss = lambda x: Loss(x, self.A)\n",
    "            \n",
    "        self.edge_index = edge_index.to(self.device)\n",
    "        \n",
    "        if normalize_A:\n",
    "            degs = self.A.sum(dim=1) \n",
    "            self.DA = torch.diag(1/(1e-1+degs)) @ self.A \n",
    "        else:\n",
    "            self.DA = self.A\n",
    "            \n",
    "        n = len(self.A)\n",
    "        # =====  Module Parameters ======\n",
    "        self.latent = nn.Parameter(torch.empty(n,feat_dims[0]).to(self.device))\n",
    "        r = n**(1./feat_dims[0])\n",
    "        print(\"latent radius {:.3g}\".format(r))\n",
    "        nn.init.normal_(self.latent,std = r)\n",
    "        \n",
    "        #self.gcn_list = nn.ModuleList([GCN_class(feat_dims[i], feat_dims[i+1], A=self.DA).to(self.device)\n",
    "         #                              for i in range(len(feat_dims)-2)])\n",
    "\n",
    "        if GCN_class == 'GCNConv':\n",
    "          self.gcn_list = nn.ModuleList([GCNConv(feat_dims[i], feat_dims[i+1], improved= True, bias = False ).to(self.device)\n",
    "                                        for i in range(len(feat_dims)-2)])\n",
    "        if GCN_class == 'GATConv':\n",
    "          self.gcn_list = nn.ModuleList([GATConv(feat_dims[i], feat_dims[i+1], bias = False).to(self.device)\n",
    "                                         for i in range(len(feat_dims)-2)])\n",
    "\n",
    "        if GCN_class == 'GraphNet':\n",
    "          self.gcn_list = nn.ModuleList([NodeModel(feat_dims[i], feat_dims[i+1]).to(self.device)\n",
    "                                         for i in range(len(feat_dims)-2)])\n",
    "        \n",
    "        \n",
    "        self.projection_layer = (nn.Linear(sum(feat_dims[:-1]), feat_dims[-1]).to(self.device)\n",
    "                                 if len(feat_dims)>1 else nn.Identity())\n",
    "        self.loss_history = []\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr = lr/2)\n",
    "        \n",
    "        self.fine_pos = nn.Parameter(torch.empty(n,feat_dims[-1]).to(self.device))\n",
    "        nn.init.normal_(self.fine_pos,std = r)\n",
    "        self.optim_fine = torch.optim.Adam([self.fine_pos], lr = lr)\n",
    "        \n",
    "    def forward(self,):\n",
    "        out = [self.latent]\n",
    "        for g in self.gcn_list:\n",
    "            out += [g(out[-1], self.edge_index)]\n",
    "        out = torch.concat(out,dim = 1)\n",
    "        out = self.projection_layer(out)\n",
    "        return out\n",
    "    \n",
    "    @time_it\n",
    "    def train(self,gcn_steps=200, fdl_steps=2000, early_stop_check_steps = 100, \n",
    "              min_steps=100, #stop_delta_ratio = 5e-3, \n",
    "              gcn_stop_threshold = 2e-2,\n",
    "              fdl_stop_threshold = 5e-3,\n",
    "              **stop_kws):\n",
    "        \"\"\"train(self,gcn_steps=200, fdl_steps=2000, early_stop_check_steps = 100, \n",
    "              min_steps=100, #stop_delta_ratio = 5e-3, \n",
    "              gcn_stop_threshold = 2e-2,\n",
    "              fdl_stop_threshold = 5e-3,\n",
    "              **stop_kws):\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if gcn_steps > 0 and len(self.gcn_list) > 0:\n",
    "                self.train_gcn(steps=gcn_steps, early_stop_check=early_stop_check_steps, \n",
    "                               min_steps=min_steps, \n",
    "                               stop_delta_ratio=gcn_stop_threshold, **stop_kws)\n",
    "                self.fine_pos.data = self()\n",
    "            print(f'\\nFDL training {fdl_steps} steps')\n",
    "            self.train_fine(steps=fdl_steps, early_stop_check=early_stop_check_steps, \n",
    "                            min_steps=min_steps, \n",
    "                            stop_delta_ratio=fdl_stop_threshold, **stop_kws)\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nTraining interrupted')\n",
    "            return\n",
    "        \n",
    "    \n",
    "    @time_it\n",
    "    def train_gcn(self,steps = 100, early_stop_check = 100, min_steps=100, stop_delta_ratio = 5e-3, **stop_kws):\n",
    "        for i in range(steps):\n",
    "            self.optim.zero_grad()\n",
    "            # loss = Loss(self(), self.A)\n",
    "            loss = self.Loss(self())\n",
    "            loss.backward() \n",
    "            self.loss_history += [loss.item()+0.]\n",
    "            self.optim.step()\n",
    "            if i> min_steps and i % early_stop_check == 1:\n",
    "                # print('checking', i)\n",
    "                if early_stopping(self.loss_history,stop_delta_ratio=stop_delta_ratio, **stop_kws): \n",
    "                    print('\\n===========\\nstopping at step ',i)\n",
    "                    break\n",
    "    \n",
    "    @time_it    \n",
    "    def train_fine(self,steps = 100, early_stop_check = 100, min_steps=100, stop_delta_ratio = 5e-3, **stop_kws):\n",
    "        for i in range(steps):\n",
    "            self.optim_fine.zero_grad()\n",
    "            # loss = Loss(self.fine_pos, self.A)\n",
    "            loss = self.Loss(self.fine_pos)\n",
    "            loss.backward() \n",
    "            self.loss_history += [loss.item()+0.]\n",
    "            self.optim_fine.step()\n",
    "            if i> min_steps and i % early_stop_check == 1:\n",
    "                # print('checking', i)\n",
    "                if early_stopping(self.loss_history,stop_delta_ratio=stop_delta_ratio, **stop_kws): \n",
    "                    print('\\n===========\\nstopping at step ',i)\n",
    "                    break\n",
    "                    \n",
    "    def get_node_pos(self):\n",
    "        return self.fine_pos\n",
    "    \n",
    "    def save_layout(self,save_dir='./', save_name = 'nodes', delimiter=','):\n",
    "        \"\"\"saves a nodes.csv \"\"\"\n",
    "        pos = V(self.get_node_pos())\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        savetxt(os.path.join(save_dir, save_name+'.csv'), pos, delimiter=delimiter)\n",
    "        \n",
    "        # TBA: create edgelist if not made\n",
    "        # savetxt(os.path.join(save_dir, 'edges.csv'), self.edgelist, delimiter=delimiter)\n",
    "            \n",
    "            \n",
    "\n",
    "def early_stopping(metric_list,\n",
    "            small_window = 32,\n",
    "            big_window = 1000,\n",
    "            stop_delta_ratio = 1e-3, verbose=True):\n",
    "    if len(metric_list) < 2*small_window:\n",
    "        return False\n",
    "    # check if chenges within big window and small window are smaller then the ratio\n",
    "    big_window = max(big_window, 2*small_window)\n",
    "    last = mean(metric_list[-small_window:])\n",
    "    dl_small =  abs(last - mean(metric_list[-2*small_window:-small_window]))\n",
    "    idx = max(0,len(metric_list)-big_window)\n",
    "    dl_big = abs(last - mean(metric_list[idx:idx+small_window]))\n",
    "    ratio = dl_small / dl_big\n",
    "    if verbose: \n",
    "        print(f'step: {len(metric_list)}, Loss change ratio: {ratio:.3g}', end='\\r')\n",
    "        # print(f'Loss change ratio: {ratio:.3g}', end='\\r')\n",
    "    return ratio < stop_delta_ratio \n",
    "\n",
    "def plot_layout(res, dims=[0,1], edges=True, node_kws={}, edg_kws=dict(c='k',lw=.5)):\n",
    "    x = res.get_node_pos()\n",
    "    # subplot(aspect='equal')\n",
    "    scatter(*V(x).T[dims], zorder = 1000, **node_kws)\n",
    "    if edges: \n",
    "        for i,j in  zip(*torch.where(res.A)):\n",
    "            plot(*V(x[[i.item(),j.item()]]).T[dims], **edg_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl_file(filename):\n",
    "    return nx.read_gpickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space dimensions\n",
    "DIMENSIONS = 3\n",
    "\n",
    "# choose GCN small steps\n",
    "MAX_GCN_STEPS = int(2e3)\n",
    "\n",
    "# fine-tuning FDL steps. make large\n",
    "MAX_FDL_STEPS = int(2e4)\n",
    "\n",
    "# early stopping (lower = runs longer)\n",
    "GCN_STOP_THRESHOLD = 5e-3\n",
    "FDL_STOP_THRESHOLD = 2e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"graphs/erdos_renyi/\"\n",
    "files = os.listdir(data_path)\n",
    "files = files[:10]\n",
    "\n",
    "\n",
    "e = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "latent radius 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"d:\\anaconda3\\envs\\pdm\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"d:\\anaconda3\\envs\\pdm\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(e):\n\u001b[0;32m     25\u001b[0m   \u001b[39m###\u001b[39;00m\n\u001b[0;32m     26\u001b[0m   \u001b[39m#layout = ResGCN(feat_dims=[100,100,DIMENSIONS], A= a, edge_index=edge_index, lr=1e-1, GCN_class='GCNConv')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m   \n\u001b[0;32m     39\u001b[0m   \u001b[39m###\u001b[39;00m\n\u001b[0;32m     40\u001b[0m   layout \u001b[39m=\u001b[39m ResGCN(feat_dims\u001b[39m=\u001b[39m[\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,DIMENSIONS], A\u001b[39m=\u001b[39m a, edge_index\u001b[39m=\u001b[39medge_index, lr\u001b[39m=\u001b[39m\u001b[39m1e-1\u001b[39m, GCN_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraphNet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m   start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()  \n\u001b[0;32m     43\u001b[0m   layout\u001b[39m.\u001b[39mtrain(gcn_steps\u001b[39m=\u001b[39mMAX_GCN_STEPS, fdl_steps\u001b[39m=\u001b[39mMAX_FDL_STEPS, \n\u001b[0;32m     44\u001b[0m         early_stop_check_steps \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, \n\u001b[0;32m     45\u001b[0m         min_steps\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, \n\u001b[0;32m     46\u001b[0m         gcn_stop_threshold \u001b[39m=\u001b[39m GCN_STOP_THRESHOLD,\n\u001b[0;32m     47\u001b[0m         fdl_stop_threshold \u001b[39m=\u001b[39m FDL_STOP_THRESHOLD,\n\u001b[0;32m     48\u001b[0m        )\n\u001b[0;32m     50\u001b[0m   results \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [[ \u001b[39m'\u001b[39m\u001b[39mGraphNet\u001b[39m\u001b[39m'\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time, layout\u001b[39m.\u001b[39mloss_history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] ]] \n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(e):\n\u001b[0;32m     25\u001b[0m   \u001b[39m###\u001b[39;00m\n\u001b[0;32m     26\u001b[0m   \u001b[39m#layout = ResGCN(feat_dims=[100,100,DIMENSIONS], A= a, edge_index=edge_index, lr=1e-1, GCN_class='GCNConv')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m   \n\u001b[0;32m     39\u001b[0m   \u001b[39m###\u001b[39;00m\n\u001b[0;32m     40\u001b[0m   layout \u001b[39m=\u001b[39m ResGCN(feat_dims\u001b[39m=\u001b[39m[\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,DIMENSIONS], A\u001b[39m=\u001b[39m a, edge_index\u001b[39m=\u001b[39medge_index, lr\u001b[39m=\u001b[39m\u001b[39m1e-1\u001b[39m, GCN_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraphNet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m   start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()  \n\u001b[0;32m     43\u001b[0m   layout\u001b[39m.\u001b[39mtrain(gcn_steps\u001b[39m=\u001b[39mMAX_GCN_STEPS, fdl_steps\u001b[39m=\u001b[39mMAX_FDL_STEPS, \n\u001b[0;32m     44\u001b[0m         early_stop_check_steps \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, \n\u001b[0;32m     45\u001b[0m         min_steps\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, \n\u001b[0;32m     46\u001b[0m         gcn_stop_threshold \u001b[39m=\u001b[39m GCN_STOP_THRESHOLD,\n\u001b[0;32m     47\u001b[0m         fdl_stop_threshold \u001b[39m=\u001b[39m FDL_STOP_THRESHOLD,\n\u001b[0;32m     48\u001b[0m        )\n\u001b[0;32m     50\u001b[0m   results \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [[ \u001b[39m'\u001b[39m\u001b[39mGraphNet\u001b[39m\u001b[39m'\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time, layout\u001b[39m.\u001b[39mloss_history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] ]] \n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pdm\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pdm\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[0;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "save_dir = \"layouts/\"\n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "os.makedirs(save_dir)\n",
    "results = []\n",
    "\n",
    "for f in files:\n",
    "  g = read_pkl_file(os.path.join(data_path, f))\n",
    "\n",
    "  n = len(g.nodes())\n",
    "  # adjacency matrix\n",
    "  a = torch.zeros(n,n)\n",
    "  identity = torch.eye(n)\n",
    "  # edgelist  \n",
    "  edg = []\n",
    "  for k,v in g.adj.items():\n",
    "      for i in v:\n",
    "          a[k,i] = 1\n",
    "          edg += [[k,i]]\n",
    "\n",
    "  edge_index = torch.tensor(edg).T\n",
    "\n",
    "  for run in range(e):\n",
    "    ###\n",
    "    #layout = ResGCN(feat_dims=[100,100,DIMENSIONS], A= a, edge_index=edge_index, lr=1e-1, GCN_class='GCNConv')\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    #layout.train(gcn_steps=0, fdl_steps=MAX_FDL_STEPS, \n",
    "    #      early_stop_check_steps = 100, \n",
    "    #      min_steps=200, \n",
    "    #      gcn_stop_threshold = GCN_STOP_THRESHOLD,\n",
    "    #      fdl_stop_threshold = FDL_STOP_THRESHOLD,\n",
    "    #     )\n",
    "    #results += [[ 'FDL', time.time() - start_time, layout.loss_history[-1] ]] \n",
    "\n",
    "    #layout.save_layout(save_dir='/content/drive/MyDrive/GCN_reparametrization/data', save_name = 'FDL_short_'+f+str(run) )\n",
    "    \n",
    "    ###\n",
    "    layout = ResGCN(feat_dims=[100,100,DIMENSIONS], A= a, edge_index=edge_index, lr=1e-1, GCN_class='GraphNet')\n",
    "\n",
    "    start_time = time.time()  \n",
    "    layout.train(gcn_steps=MAX_GCN_STEPS, fdl_steps=MAX_FDL_STEPS, \n",
    "          early_stop_check_steps = 100, \n",
    "          min_steps=200, \n",
    "          gcn_stop_threshold = GCN_STOP_THRESHOLD,\n",
    "          fdl_stop_threshold = FDL_STOP_THRESHOLD,\n",
    "         )\n",
    "    \n",
    "    results += [[ 'GraphNet', time.time() - start_time, layout.loss_history[-1] ]] \n",
    "    \n",
    "    layout.save_layout(save_dir=save_dir, save_name = 'GraphNet_short_'+f+str(run) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = [1,3,2]\n",
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
